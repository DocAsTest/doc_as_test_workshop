
ifndef::htmlformat[]
:page_extension: adoc
endif::[]

ifdef::htmlformat[]
:page_extension: html
endif::[]


ifdef::htmlformat[]
:toc: left
endif::[]

:doc_as_test: https://sfauvel.github.io/documentationtesting/[DocAsTest]
:asciidoc: https://docs.asciidoctor.org/asciidoc/latest/[Asciidoc] 

:sectnums:
:sectanchors:
:source-highlighter: rouge

= Doc as Test workshop


image:qr_code_workshop_fr.svg[link="qr_code_workshop.{page_extension}", width=100px]

== Introduction



Cet atelier vise à *expérimenter l'approche {doc_as_test}*.
Vous pouvez trouver des informations et des ressources sur ce concept sur le site {doc_as_test}.

En bref, *chaque méthode de test génère un paragraphe décrivant un comportement*.
L'agrégation de tous ces paragraphes constitue une documentation complète du produit.
*Le test passe si le texte produit est identique au dernier* qui a été validé. 
Dans le cas contraire, un comportement a changé et le test échoue. 
Il faut alors soit corriger le code (_régression_), soit valider le nouveau texte (_évolution_).

Dans cet atelier, nous allons documenter un projet et par la même occasion le tester.
Vous pouvez utiliser *n'importe lequel de vos projets* pour cet atelier.
Le plus important, c'est d'*être à l'aise avec votre environnement de développement* pour vous concentrer sur la démarche.
Vous devez juste être en mesure d'exécuter des tests sur ce projet et vous devez pouvoir écrire un fichier sur votre disque à partir de ceux çi.
Il pourrait également être intéressant (mais pas nécessairement) de pouvoir le pousser dans un dépôt Github public pour publier la documentation finale et la partager avec les autres participants.

Si vous n'avez pas de projet, vous pouvez cloner ce dépôt : link:https://github.com/sfauvel/Parrot-Refactoring-Kata[]. 
Il s'agit d'un clone du kata présent sur le Github d'https://github.com/emilybache[Emily Bache].

Ce kata est disponible dans de nombreux langages, vous trouverez donc probablement votre préféré. 
Nous avons configuré le projet java avec un outillage assez compet. 
Les projets python, javascript et typescript sont également configurés pour démarrer rapidement.


== Outillage

====
Nous allons tout d'abord préparer l'environnement nécessaire à la mise en place d'une approche {doc_as_test}.
Pour cela nous verrons les base de la syntaxe `{asciidoc}`, le langage de markup qui nous servira à produire les documents
que nous consulterons à travers un `visualiseur`.
Nous mettrons ensuite en place les outils pour assurer la validation du contenu de la documentation.  
====


=== Installer un viewer


Installez un viewer `{asciidoc}` pour visualiser le rendu des fichiers asciidoc sur lesquels nous allons travailler.
Préférez une installation sur votre IDE pour visualiser le résultat lors du développement.


[%collapsible]
.Liste de Viewer
====
* Intellij/PyCharm: plugin
** https://plugins.jetbrains.com/plugin/7391-asciidoc[AsciiDoc plugin]
* VSCode
** https://marketplace.visualstudio.com/items?itemName=asciidoctor.asciidoctor-vscode[AsciiDoc extension]
* Web navigator
** https://addons.mozilla.org/fr/firefox/addon/asciidoctorjs-live-preview/[Firefox - Asciidoctor.js Live Preview]
** https://chrome.google.com/webstore/detail/asciidoctorjs-live-previe/iaalpfgpbocpdfblpnhhgllgbdbchmia[Chrome - Asciidoctor.js Live Preview]
** https://microsoftedge.microsoft.com/addons/detail/asciidoctorjs-live-previ/pefkelkanablhjdekgdahplkccnbdggd[Edge - Asciidoctor.js Live Preview]
====

=== Créer un document

Nous allons écrire notre premier fichier en `{asciidoc}`.
Pour cela, créez un fichier `workshop.adoc`. 
L'extension `.adoc` est utilisée pour les fichiers au format `{asciidoc}`.

Décrivez y l'atelier dans lequel nous sommes avec quelques informations telles que:

* Un titre
* Une petite description de ce que vous attendez de cet atelier.
* Les liens vers des ressources utiles.
* Un tableau avec quelques informations sur vous et les personnes avec qui vous faites l'atelier (nom, pseudo, twitter, ).

N'hésitez pas à mettre en forme le texte pour obtenir un rendu agréable.

Vous trouverez des exemples des syntaxes de base sur la link:asciidoc.{page_extension}[page d'exemple] ou , de manière plus complète, sur la page link:https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/[syntax-quick-reference] du site `{asciidoc}`.


=== Publier un site


Cette étape n'est pas indispensable pour cet atelier mais elle est intéressante pour goûter à la sensation d'avoir une documentation à jour et accessible par tous en continu.

Nous allons configurer, sur un dépôt github, une action qui publie le contenu de notre documentation.


[%collapsible]
.Publier un site web à partir de fichiers `{asciidoc}` en utilisant les Github Actions
======
include::asciidoc_to_html.adoc[leveloffset=+1,tags=github-configure]
include::asciidoc_to_html.adoc[leveloffset=+1,tags=github-create-action]
include::asciidoc_to_html.adoc[leveloffset=+1,tags=github-publish]
======

Vous pouvez également consulter la page link:asciidoc_to_html.{page_extension}[Asciidoc vers HTML] qui décrit d'autres manières de générer des pages HTML.

=== Outillage pour {doc_as_test}

====
L'objectif est de valider que la documentation est cohérente avec le comportement de l'application.
Pour cela, nous allons nous appuyer sur notre framework de test habituel.
Chaque test génerera le contenu d'un chapitre et vérifiera qu'il est identique à la précédente version qui a été validée.
C'est une combinaison des techniques de `Living documentation` et de `Golden Master`.
====

// === Living documentation
// 
// Le principe de `Living documentation` est d'extraire les informations depuis le code pour générer une documentation en permanence synchronisée avec le code.
// 
// Ce qui va particulièrement nous intéressé ici, c'est de récupérer les comportements de l'application. 
// Pour cela, on va exécuter du code et écrire dans un fichier le déroulement du scénario ainsi que les résultats obtenus.
// On pourra utiliser le format `{asciidoc}` pour avoir un rendu visuel agréable.
// 
// === Golden Master
// 
// Le principe de l'approche `Golden Master` est de vérifier la non régression d'une application en comparant les résultats produits par une version de référence avec ceux de la version à valider.
// 
// On peut pour cela faire tourner les deux versions en parallèle et comparer les résultats. 
// 
// On peut aussi, et c'est ce que nous allons utiliser, générer avec la version de référence une trace de ce qui s'est produit durant l'exécution.
// Il suffira ensuite de vérifier que la nouvelle version produit la même sortie.


Il y a plusieurs manières de configurer l'outillage minimal nécessaire à cet atelier. 
Choisissez-en une rapide à mettre en place pour vous concentrer sur l'expérimentation de la méthode quitte à avoir un outillage rudimentaire dans un premier temps.

* *<<_approvals>>*: Le plus simple si vous utilisez le kata en Java, Javascript, Typescript ou Python car *tout est déjà configuré*.

* *<<_méthode_de_validation>>*: Ecrire une méthode de vérification à appeler à la fin de vos tests. Cela ne nécessite qu'un *petit développement simple pour obtenir un outillage pleinement utilsable*.
* *<<_script_bash_et_git>>*: Vous n'avez qu'à générer, depuis vos tests, votre document dans votre repo Git et un script bash fourni fera la reste. C'est *très simple mais la validation est faite par le script et non par vos tests* et donc moins intégré à votre environnement de développement.


==== Approvals

Vous pouvez utiliser la librairie https://approvaltests.com/[Approvals] qui est faite pour valider des contenus par rapport à une version de référence et qui est disponible dans plusieurs langages.

[NOTE]
====
Dans le kata `Parrot`, nous avons configuré cette bibliothèque pour les projets Java, Javascript, Typescript et Python, ce qui vous permet de démarrer rapidement.
====

Si vous devez l'utiliser sur votre projet ou pour d'autres langages que ceux préconfiguré, vous devrez le type d'extension des fichiers de sortie pour produire des `.adoc` et non des `.txt`.
Cela peut être un peu fastidieux et dans ce cas, il est préférable, pour cet atelier, d'utiliser l'une des deux autres façons de faire que nous vous présentons ensuite

`Approvals` utilise un fichier `.approved` comme référence attendue. 
Tant que votre contenu est différent de ce fichier, un fichier `.received` est généré ce qui vous permet de comparer le résultat obtenu avec celui attendu. 
Si le fichier `.received` correspond à ce que vous voulez, il vous suffit de le renommer ou de copier son contenu dans le fichier `.approved` pour valider la nouvelle référence.


==== Méthode de validation

Si vous ne souhaitez pas intégrer https://approvaltests.com/[Approvals],
vous pouvez écrire une méthode qui fait l'équivalent assez rapidement et ce sera suffisant pour nos besoins.

Vous trouverez ci-dessous l'algorithme, à adapter selon votre langage, et qui permet de faire la validation du contenu par rapport à un fichier de référence.
Il faudra appeler cette méthode à la fin de chacun de vos tests.

[source, python]
----
def verifier(nom_fichier, contenu_reçu):
  fichier_reçu     = nom_fichier + "received.adoc"
  fichier_approuvé = nom_fichier + "approved.adoc"

  supprimer fichier_reçu s'il existe

  si fichier_approuvé n'existe pas ou contenu_approuvé != contenu_reçu:
    créer fichier_reçu avec contenu_reçu
    fail
----


==== Script bash et Git

Vous pouvez vous contenter de laisser Git vérifier les modifications dans vos documents.
Nous fournissons un script `checkDocInFolder.sh` dans le dossier `scripts`
qui appelle des commandes Git pour détecter les fichiers modifiés dans le répertoire indiqué. 
Ces fichiers, générés depuis vos tests, et qui ont un contenu qui a changé, sont considérés comme des tests en échec.

Pour valider un fichier et en faire la nouvelle référence, il vous suffit de l'ajouter dans les fichiers `staged` avec la commande `git add [filename]`.

.Exemple d'utilisation du script de vérification
----
bash scripts/checkDocInFolder.sh  ./Python/docs
----

Pour info, le script utilise la commande git suivante pour détecter les fichiers modifiés :
----
git status -s --no-renames [DOSSIER]
----


== {doc_as_test}

====
Nous allons vous guider à travers une suite d'étape en se basant sur le https://github.com/sfauvel/Parrot-Refactoring-Kata[kata de refactoring Parrot].
Vous pouvez tout aussi bien utiliser un de vos projets et adapter les étapes à votre contexte.
L'important est d'expérimenter l'approche et de se faire une idée de son utilisation.
====

=== Démarche

Une fois l'outillage mis en place, nous allons pouvoir *documenter l'application*.
Nous vous indiquons une suite d'étapes à suivre à titre d'exemple. 
N'hésitez pas à explorer d'autres pistes si vous en avez envie.

. Pensez avant tout que *vous produisez de la documentation*. 
Elle doit-être lisibile, compréhensible et contenir toutes les informations nécessaires pour valider me fonctionnement de votre application.
. Voyez *chaque test comme l'écriture d'un chapitre* et pas seulement comme la validation d'un cas isolé.
Vous pouvez regrouper, dans un seul test, plusieurs cas que vous auriez habituellement séparés.
. N'oubliez pas que *vous n'êtes pas en train de faire du TDD*.
Ne vous laissez pas restreindre par l'appplication strict de l'approche TDD.
. Vous n'êtes pas obligé d'approuver le document systématiquement avant de lancer le test.
Vous pouvez attendre d'obtenir le résultat qui vous convient visuellement avant d'en faire une référence.
. N'hésitez pas à *créer de petits utilitaires* pour vous aider à l'écriture en {asciidoc} ou pour représenter les concepts métier et l'état du système.
. A terme, les fichiers `.approved` sont commités avec le projet car ils servent d'assertion pour les tests.

//
// - The `area`.
// - Position of the `parrot` and its speed.
// - Positions of items in `area`.




// For this workshop, we will use the famous link:https://github.com/emilybache/GildedRose-Refactoring-Kata[GildedRose-Refactoring-Kata]. 
// It's an exercise to practice at handling legacy code. 
// That what we will done by creating a description of the behaviors and by creating a test harness in the same time.
// We won't try to improve the code here.
// This is not the point of this workshop but I encourage you to do it in a second time.
// 
// This kata is declined on a lot of language so you can chose the one you prefer.
// 
// other multilanguage kata: 
// 
// * https://github1s.com/emilybache/Refactoring-Kata-Lift-Pass-Pricing: WebServer, Mathematic calculation, json response
// * https://github.com/emilybache/Parrot-Refactoring-Kata: simple calculation, default values
// * https://github.com/emilybache/Theatrical-Players-Refactoring-Kata: Calculation but Nothing to extract
// * https://github.com/emilybache/SupermarketReceipt-Refactoring-Kata: Algorithm
// * https://github1s.com/emilybache/FantasyBattle-Refactoring-Kata/: Not a lot of algo. It may interesting to list added Items
// * https://github1s.com/emilybache/Racing-Car-Katas: LeaderBoard or Alarm
// * https://github.com/emilybache/Theatrical-Players-Refactoring-Kata

// === Extraire des infos
// 
// La documentation vivante est une documentation générée à partir de code dont la mise à jour est garantie.
// Au lieu de créer cette documentation à partir d'un programme, nous allons utiliser nos tests comme autant de programmes pour générer les paragraphes de notre documentation.
// 
// 
// 
// * Utilisez un test pour générer un fichier (d'extension 'adoc') contenant des informations issues de l'exécution du code de l'application. 
// Si vous utilisez le Parrot kata avec Java, Javascript, Typescript ou Python, il existe déjà un test qui génère un fichier. 
// Les tests échoueront mais nous verrons comment les faire passer dans le chapitre suivant.
// * Écrivez dans ce fichier la liste des perroquets ainsi que leur vitesse par défaut.
// * Améliorez la rédaction pour avoir un document agréable à lire.

=== Documenter le code existant

====
Nous allons documenter le code existant et mettre en évidence le comportement actuel.
====

. Afficher la liste des perroquets existant, si possible, en parcourant cette liste par programmation.
. Ajouter une image pour chaque perroquet (images disponibles dans le dossier `image`).
. Faire un tableau avec la vitesse de chaque perroquet à l'initialisation. 
Utiliser les mêmes paramètres pour chaque perroquet et indiquez ces valeurs dans le document.
. Pour le perroquet `Norwegian Blue`, afficher sa vitesse en fonction du voltage par pas de 0.1. 
. Transformer ce tableau pour l'afficher en ligne (voltage sur la première ligne et vitesse sur la seconde).

=== Créer de nouvelles fonctionnalités

====
Nous allons utiliser l'approche lors de la mise en place de nouvelles fonctionnalités.
====

Nous voulons modéliser une `zone` dans laquelle les perroquets peut voyager. 
Des `sources d'énergie` sont placées à différents endroits de cette `zone`.
Elles ont une puissance comprise entre 0 et 2. +
Le perroquet est placé quelque part dans cette `zone`.
Il peut se déplacer dans les différentes directions sans pouvoir sortir de la `zone`.
A chaque mouvement, son voltage diminue de 0,1. 
Lorsqu'il passe sur une source d'énergie, il augmente son voltage de la puissance de le source d'énergie et celle çi disparait. 

. Affichez une table qui va représenter la `zone`.
. Indiquee les sources d'énergie et leur puissance.
. Localisez l'emplacement du perroquet.
. Documentez la fonction de déplacement.
. Mettez en évidence l'évolution du voltage du perroquet lors de ces déplacements.
. Montrez ce qu'il se passe lorsqu'il passe sur une source d'énergie.


// == Golden Master
// 
// ====
// Maintenant, nous avons une documentation synchronisée avec le comportement réel du code. 
// La dernière étape consiste à détecter la régression en utilisant l'approche `Golden Master`.
// ====
// 
// 
// Maintenant, vous avez un fichier qui a capturé le comportement de l'application à un moment donné. Si vous relancez le test, le résultat devrait être le même. Sinon, cela signifie qu'il y a une régression depuis la dernière exécution.
// 
// Ainsi, à la fin de notre test, nous pouvons comparer le dernier fichier généré avec la nouvelle version que nous produisons. S'ils sont identiques, c'est bien. Si ce n'est pas le cas, nous n'avons qu'à faire échouer notre test.
// 
// Nous expliquons plusieurs façons de le faire.
// 
// 
// 
// 
// === Valider le comportement existant
// 
// Nous allons créer un autre chapitre pour voir ce qu'il advient d'un build de perroquet avec des paramètres différents.
// 
// Nous voulons comprendre quel est l'impact de la tension sur la vitesse du Norwegian Blue.
// 
// Réfléchissez d'abord au type de description que vous voulez voir. 
// De quelles valeurs avez-vous besoin pour comprendre ce qui se passe ? 
// Quelles valeurs d'entrée et de sortie ? 
// Les actions exécutées ? 
// Essayez ensuite de le présenter de manière à ce que le comportement puisse être rapidement compris.
// 
// 
// * Add specification and specific description
// * Doc by item, by attribute
// * Graph by item, all the items
// * Make one file per document and organize them
// 
// * Possible path
// ** Display a graph to show the result
// ** Show values until max
// ** Document Norwegian blue
// ** Create a test for african parrot
// ** Use an iteration over enum values
// ** Display all parrot types
// ** Create a formatter for a table line
// ** Display in a table
// ** Display enum name
// ** Generate a first document
// ** Create a test file for generating doc


[%collapsible]
.Autres exercices
====
. Ajoutez un nouveau type de perroquet.
. Refactorer le code de production une fois couvert par vos tests.
. Calculez le temps mis par le perroquet pendant son trajet.
. Créez un document présentant le fonctionnement général à travers un ou deux cas et faites des liens vers d'autres pages contenant le détail complet des comportements.
. Créez un rapport JSON de l'état du système.
. Écrivez un algorithme qui déplace le perroquet pour qu'il consomme toutes les sources d'énergie.
====


//
// - The `area`.
// - Position of the `parrot` and its speed.
// - Positions of items in `area`.



// When we developing the formatter, you don't need to approved the file until it looks like you want. 
// Just work on the received file and approve it when you are satisfied with the result.
// Start by creating a formatter that display what you need to see about the state of the system.
// 
// 
// Don't try to make something too sophisticated. 
// We want to work on the representation more than on the code design.
// It doesn't matter if the code is far from good practice, you can always improve it later.
// 
// Remember that we are not doing TDD. 
// Try to forget good testing practices and focus on what you need to produce to allow you to validate.
// 
// You don't need to have the expected result (the approved file) before you are writing the code.
// You can just look at the result without validating it until the content corresponds to what you expect.
// 
// A test method is responsible for generating a chapter, not testing a single case.



// What we want to develop another Parrot. 
// 
// * put one item in a place
// * put several items from a place (what happen if there is no place ?) 
// * continue on next line other direction if not enough place
// * auto place
// ** Search first place where it could be stored
// ** Prefer on the same line.
// ** Prefer near other same items.
// ** The goal is to form the biggest group of the same item not necessary on the same line.
// 

//  ! Do not make another javadoc
//   Static extraction (when code change, doc is updated) : option list, class list inherit from a specific class(connector, ...), docs list, conf files or scripts, glossary.
// 
//   Dynamic extraction executing code (default values, error messages,...) 
//   Formatting the text
// 
// 
// * Generate from a test
//   Approval (or git) 
// * let's play
//   Retro doc
//   New development (not tdd => visually check  the result as debugging)
// 
// Develop focusing on visualize the result

// == Conclusion
// 
// 
// Vous pouvez envoyer l'url de votre site sur les réseaux sociaux (Twitter : #DocAsTest).
// 
// Nous discuterons de vos sentiments après cette expérience.
// 
// Merci à tous pour votre participation.


== Resources

[glossary]
Cet atelier::             https://sfauvel.github.io/doc_as_test_workshop/[]
Parrot Kata::               https://github.com/sfauvel/Parrot-Refactoring-Kata[]
Asciidoc::                  https://docs.asciidoctor.org/asciidoc/latest/[]
Asciidoc quick reference::  https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/[]
Living documentation::
  https://www.youtube.com/watch?v=Tw-wcps7WqU[Living Documentation : vous allez aimer la documentation !] -  Cyrille Martraire à Devoxx FR +
  https://www.eyrolles.com/Informatique/Livre/living-documentation-9780134689326/[Living Documentation] - Livre de Cyrille Martraire
Approvals::                 https://approvaltests.com/[]
DocAsTest::                 
  https://sfauvel.github.io/documentationtesting/[] +
  https://www.youtube.com/watch?v=1slYI-dBMcc[Human talk (video 10mn in French)] +
  https://www.youtube.com/watch?v=AQDILnknTJ0&feature=youtu.be[Bdx/IO (video 45mn in French)]
